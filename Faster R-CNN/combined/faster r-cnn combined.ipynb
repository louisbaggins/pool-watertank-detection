{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["ssJsHbpsIh7e","brokvg9kINKF","rYV1DDi8H8Ci","BR22QCNiL6xr","BuOc4rP0M_ev","qk05C2HKNTgA","_qsmYYr6Ro6y"],"machine_shape":"hm","gpuType":"L4","mount_file_id":"13TEe0mkiyrYc-b5ukIK5rFr7EsmnWB2r","authorship_tag":"ABX9TyN8twUf0mFI+M5xa49gf3Kw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Faster R-CNN"],"metadata":{"id":"F5copuR1-gzi"}},{"cell_type":"markdown","source":["## Instala depend√™ncias e define vari√°veis globais"],"metadata":{"id":"KCmDMvFiE97M"}},{"cell_type":"code","source":["!pip install -q albumentations==1.4.6 opencv-python pycocotools tqdm\n","!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n","!pip install -q pycocotools albumentations==1.4.6 opencv-python tqdm\n","!pip uninstall -y sympy\n","!pip install sympy --upgrade"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"L7Q_QXKrE3gx","executionInfo":{"status":"ok","timestamp":1762495407403,"user_tz":180,"elapsed":28292,"user":{"displayName":"Luis Felipe","userId":"08242572504466589884"}},"outputId":"2cc7edf2-35c0-4274-f2d3-1a89dbd04936"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/153.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m153.5/153.5 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hFound existing installation: sympy 1.13.3\n","Uninstalling sympy-1.13.3:\n","  Successfully uninstalled sympy-1.13.3\n","Collecting sympy\n","  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy) (1.3.0)\n","Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m83.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sympy\n","Successfully installed sympy-1.14.0\n"]}]},{"cell_type":"markdown","source":["Define vari√°veis globais iniciais"],"metadata":{"id":"8gVDKXh6-1We"}},{"cell_type":"code","source":["import sys\n","sys.path.append(\"/content/drive/MyDrive/TCC/src/\")"],"metadata":{"id":"pqDgMPRYCKZ6","executionInfo":{"status":"ok","timestamp":1762495407413,"user_tz":180,"elapsed":2,"user":{"displayName":"Luis Felipe","userId":"08242572504466589884"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","execution_count":3,"metadata":{"id":"EHmd4UI7-enm","executionInfo":{"status":"ok","timestamp":1762495407441,"user_tz":180,"elapsed":27,"user":{"displayName":"Luis Felipe","userId":"08242572504466589884"}}},"outputs":[],"source":["from pathlib import Path\n","\n","DATASET_ROOT = Path(\"/content/drive/MyDrive/TCC/DATASET\")\n","\n","paths = {\n","    \"bh_pools\": {\n","        \"images\": {\n","            \"train\": DATASET_ROOT/\"bh_pools/images/train\",\n","            \"val\":   DATASET_ROOT/\"bh_pools/images/val\",\n","            \"test\":  DATASET_ROOT/\"bh_pools/images/test\",\n","        },\n","        \"ann\": {\n","            \"train\": DATASET_ROOT/\"bh_pools/annotations/instances_train.json\",\n","            \"val\":   DATASET_ROOT/\"bh_pools/annotations/instances_val.json\",\n","            \"test\":  DATASET_ROOT/\"bh_pools/annotations/instances_test.json\",\n","        }\n","    },\n","    \"bh_watertanks\": {\n","        \"images\": {\n","            \"train\": DATASET_ROOT/\"bh_watertanks/images/train\",\n","            \"val\":   DATASET_ROOT/\"bh_watertanks/images/val\",\n","            \"test\":  DATASET_ROOT/\"bh_watertanks/images/test\",\n","        },\n","        \"ann\": {\n","            \"train\": DATASET_ROOT/\"bh_watertanks/annotations/instances_train.json\",\n","            \"val\":   DATASET_ROOT/\"bh_watertanks/annotations/instances_val.json\",\n","            \"test\":  DATASET_ROOT/\"bh_watertanks/annotations/instances_test.json\",\n","        }\n","    }\n","}"]},{"cell_type":"markdown","source":["## Define pesos e instancia model"],"metadata":{"id":"ssJsHbpsIh7e"}},{"cell_type":"code","source":["import torch\n","import torchvision\n","from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n","from torchvision.models.detection import FasterRCNN\n","from torchvision.models.detection.rpn import AnchorGenerator\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","num_classes = 1 + 2  # background + (piscina, caixa d'√°gua) ‚Üí ajuste se usar por dataset\n","\n","weights = torchvision.models.detection.FasterRCNN_ResNet50_FPN_V2_Weights.COCO_V1\n","model = torchvision.models.detection.fasterrcnn_resnet50_fpn_v2(weights=weights)\n","\n","in_features = model.roi_heads.box_predictor.cls_score.in_features\n","model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n","model.to(device)"],"metadata":{"collapsed":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"BBqC7BsBIkZh","executionInfo":{"status":"ok","timestamp":1762495417933,"user_tz":180,"elapsed":10490,"user":{"displayName":"Luis Felipe","userId":"08242572504466589884"}},"outputId":"92235eff-c5c9-4f0c-8ef2-cafcddffc7ea"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_v2_coco-dd69338a.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_v2_coco-dd69338a.pth\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 167M/167M [00:00<00:00, 197MB/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["FasterRCNN(\n","  (transform): GeneralizedRCNNTransform(\n","      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n","  )\n","  (backbone): BackboneWithFPN(\n","    (body): IntermediateLayerGetter(\n","      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","      (layer1): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","      (layer2): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (3): Bottleneck(\n","          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","      (layer3): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (3): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (4): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (5): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","      (layer4): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","    )\n","    (fpn): FeaturePyramidNetwork(\n","      (inner_blocks): ModuleList(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","        (2): Conv2dNormActivation(\n","          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","        (3): Conv2dNormActivation(\n","          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (layer_blocks): ModuleList(\n","        (0-3): 4 x Conv2dNormActivation(\n","          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (extra_blocks): LastLevelMaxPool()\n","    )\n","  )\n","  (rpn): RegionProposalNetwork(\n","    (anchor_generator): AnchorGenerator()\n","    (head): RPNHead(\n","      (conv): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","          (1): ReLU(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","          (1): ReLU(inplace=True)\n","        )\n","      )\n","      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n","      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","  )\n","  (roi_heads): RoIHeads(\n","    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n","    (box_head): FastRCNNConvFCHead(\n","      (0): Conv2dNormActivation(\n","        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","      )\n","      (1): Conv2dNormActivation(\n","        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","      )\n","      (2): Conv2dNormActivation(\n","        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","      )\n","      (3): Conv2dNormActivation(\n","        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","      )\n","      (4): Flatten(start_dim=1, end_dim=-1)\n","      (5): Linear(in_features=12544, out_features=1024, bias=True)\n","      (6): ReLU(inplace=True)\n","    )\n","    (box_predictor): FastRCNNPredictor(\n","      (cls_score): Linear(in_features=1024, out_features=3, bias=True)\n","      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["## Define transformers e collate_fn\n"],"metadata":{"id":"brokvg9kINKF"}},{"cell_type":"code","source":["import json, cv2, numpy as np, torch, albumentations as A\n","\n","def get_transforms(train=True, img_size=1024):\n","    if train:\n","        tfms = [\n","            A.LongestMaxSize(max_size=img_size),\n","            A.PadIfNeeded(img_size, img_size, border_mode=cv2.BORDER_CONSTANT, value=(114,114,114)),\n","            A.HorizontalFlip(p=0.5),\n","            A.ShiftScaleRotate(shift_limit=0.02, scale_limit=0.10, rotate_limit=10,\n","                               border_mode=cv2.BORDER_CONSTANT, value=(114,114,114), p=0.5),\n","            A.RandomBrightnessContrast(p=0.3),\n","            A.CLAHE(p=0.2),\n","        ]\n","    else:\n","        # tfms = [\n","        #     A.LongestMaxSize(max_size=img_size),\n","        #     A.PadIfNeeded(img_size, img_size, border_mode=cv2.BORDER_CONSTANT, value=(114,114,114)),\n","        # ]\n","        return None\n","    return A.Compose(\n","        tfms,\n","        bbox_params=A.BboxParams(\n","            format=\"pascal_voc\",\n","            label_fields=[\"class_labels\"],\n","            min_visibility=0.0,\n","        )\n","    )\n","def collate_fn(batch):\n","    imgs, targets = list(zip(*batch))\n","    return list(imgs), list(targets)"],"metadata":{"id":"MQo4rpvHISSr","executionInfo":{"status":"ok","timestamp":1762495419898,"user_tz":180,"elapsed":1936,"user":{"displayName":"Luis Felipe","userId":"08242572504466589884"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["## Carrega dataloaders por classe"],"metadata":{"id":"rYV1DDi8H8Ci"}},{"cell_type":"code","source":["from models.coco_dataset import CocoDetDataset\n","from torch.utils.data import Dataset, DataLoader\n","\n","\n","# ----- BH-POOLS -----\n","pools_train = CocoDetDataset(\n","    paths[\"bh_pools\"][\"images\"][\"train\"],\n","    paths[\"bh_pools\"][\"ann\"][\"train\"],\n","    transforms=get_transforms(train=True))\n","\n","pools_val   = CocoDetDataset(\n","    paths[\"bh_pools\"][\"images\"][\"val\"],\n","    paths[\"bh_pools\"][\"ann\"][\"val\"],\n","    transforms=get_transforms(train=False))\n","\n","pools_test  = CocoDetDataset(\n","    paths[\"bh_pools\"][\"images\"][\"test\"],\n","    paths[\"bh_pools\"][\"ann\"][\"test\"],\n","    transforms=get_transforms(train=False))\n","\n","\n","pools_train_loader = DataLoader(pools_train, batch_size=2, shuffle=True,  num_workers=2, collate_fn=collate_fn, pin_memory=True)\n","pools_val_loader   = DataLoader(pools_val,   batch_size=2, shuffle=False, num_workers=2, collate_fn=collate_fn, pin_memory=True)\n","pools_test_loader  = DataLoader(pools_test,  batch_size=2, shuffle=False, num_workers=2, collate_fn=collate_fn, pin_memory=True)\n","\n","print(\"BH-POOLS:\", len(pools_train), len(pools_val), len(pools_test))\n","\n","# ----- BH-WATERTANKS -----\n","wt_train = CocoDetDataset(\n","    paths[\"bh_watertanks\"][\"images\"][\"train\"],\n","    paths[\"bh_watertanks\"][\"ann\"][\"train\"],\n","    transforms=get_transforms(train=True),\n","    class_id_out=2)\n","\n","wt_val   = CocoDetDataset(\n","    paths[\"bh_watertanks\"][\"images\"][\"val\"],\n","    paths[\"bh_watertanks\"][\"ann\"][\"val\"],\n","    transforms=get_transforms(train=False),\n","    class_id_out=2)\n","\n","wt_test  = CocoDetDataset(\n","    paths[\"bh_watertanks\"][\"images\"][\"test\"],\n","    paths[\"bh_watertanks\"][\"ann\"][\"test\"],\n","    transforms=get_transforms(train=False),\n","    class_id_out=2)\n","\n","wt_train_loader = DataLoader(wt_train, batch_size=2, shuffle=True,  num_workers=2, collate_fn=collate_fn, pin_memory=True)\n","wt_val_loader   = DataLoader(wt_val,   batch_size=2, shuffle=False, num_workers=2, collate_fn=collate_fn, pin_memory=True)\n","wt_test_loader  = DataLoader(wt_test,  batch_size=2, shuffle=False, num_workers=2, collate_fn=collate_fn, pin_memory=True)\n","\n","print(\"BH-WATERTANKS:\", len(wt_train), len(wt_val), len(wt_test))\n"],"metadata":{"id":"tYh9bNrl_XIL","executionInfo":{"status":"ok","timestamp":1762495427440,"user_tz":180,"elapsed":7540,"user":{"displayName":"Luis Felipe","userId":"08242572504466589884"}},"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"outputId":"b811b21e-024f-4e19-cff5-ff5fb92def50"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["loading annotations into memory...\n","Done (t=1.84s)\n","creating index...\n","index created!\n","loading annotations into memory...\n","Done (t=0.56s)\n","creating index...\n","index created!\n","loading annotations into memory...\n","Done (t=0.70s)\n","creating index...\n","index created!\n","BH-POOLS: 125 25 50\n","loading annotations into memory...\n","Done (t=1.56s)\n","creating index...\n","index created!\n","loading annotations into memory...\n","Done (t=0.60s)\n","creating index...\n","index created!\n","loading annotations into memory...\n","Done (t=1.04s)\n","creating index...\n","index created!\n","BH-WATERTANKS: 99 25 24\n"]}]},{"cell_type":"markdown","source":["## Instancia classe COCO com datasets combinados\n","\n","Combina datasets de piscinas e caixas dagua, e instancia loader misto"],"metadata":{"id":"BR22QCNiL6xr"}},{"cell_type":"code","source":["from torch.utils.data import ConcatDataset\n","\n","train_ds = ConcatDataset([pools_train, wt_train])\n","val_ds   = ConcatDataset([pools_val, wt_val])\n","test_ds  = ConcatDataset([pools_test, wt_test])"],"metadata":{"id":"y-Mrnsn1GoXx","executionInfo":{"status":"ok","timestamp":1762495427448,"user_tz":180,"elapsed":3,"user":{"displayName":"Luis Felipe","userId":"08242572504466589884"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["BATCH_SIZE = 2\n","\n","train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,\n","                          num_workers=2, collate_fn=collate_fn, pin_memory=True)\n","val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False,\n","                          num_workers=2, collate_fn=collate_fn, pin_memory=True)\n","test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False,\n","                          num_workers=2, collate_fn=collate_fn, pin_memory=True)"],"metadata":{"id":"42DqMCNuMRjF","executionInfo":{"status":"ok","timestamp":1762495427469,"user_tz":180,"elapsed":19,"user":{"displayName":"Luis Felipe","userId":"08242572504466589884"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["## Inst√¢ncia fun√ß√µes de treinamento (fit, train_one_epoch e eval_val_loss)"],"metadata":{"id":"BuOc4rP0M_ev"}},{"cell_type":"code","source":["from tqdm import tqdm\n","import math, os\n","from pycocotools.cocoeval import COCOeval\n","\n","def train_one_epoch(model, loader, optimizer, scaler, desc=\"train\"):\n","    model.train()\n","    epoch_loss = 0.0\n","    for imgs, targets in tqdm(loader, desc=desc, leave=False):\n","        imgs = [im.to(device) for im in imgs]\n","        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n","\n","        optimizer.zero_grad(set_to_none=True)\n","        with torch.cuda.amp.autocast():\n","            loss_dict = model(imgs, targets)\n","            loss = sum(loss_dict.values())\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","\n","        epoch_loss += loss.item()\n","    return epoch_loss / max(1, len(loader))\n","\n","@torch.no_grad()\n","def eval_val_loss(model, loader, desc=\"val_loss\"):\n","    # Para calcular loss, o modelo precisa estar em .train() nos detectors do torchvision\n","    model.train()\n","    epoch_loss = 0.0\n","    for imgs, targets in tqdm(loader, desc=desc, leave=False):\n","        imgs = [im.to(device) for im in imgs]\n","        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n","        loss_dict = model(imgs, targets)\n","        loss = sum(loss_dict.values())\n","        epoch_loss += loss.item()\n","    return epoch_loss / max(1, len(loader))\n","\n","def fit(model, train_loader, val_loader, optimizer, scaler, scheduler, epochs=20, ckpt_path=\"fasterrcnn_best.pth\"):\n","    best_val = float(\"inf\")\n","    for epoch in range(1, epochs+1):\n","        train_loss = train_one_epoch(model, train_loader, optimizer, scaler, desc=f\"train[{epoch}/{epochs}]\")\n","        val_loss   = eval_val_loss(model,  val_loader,  desc=f\"val  [{epoch}/{epochs}]\")\n","        scheduler.step()\n","\n","        coco_eval = evaluate(model, val_loader, device=device)\n","        map50 = coco_eval.coco_eval['bbox'].stats[1]  # AP@0.50\n","\n","        # descongela backbone ap√≥s 2-3 √©pocas\n","        if epoch == 3:\n","            for p in model.backbone.body.parameters():\n","                p.requires_grad = True\n","            # recomputa params do otimizador (agora com backbone liberado)\n","            new_params = [p for p in model.parameters() if p.requires_grad]\n","            # LR menor ap√≥s descongelar ajuda\n","            optimizer = torch.optim.SGD(new_params, lr=0.002, momentum=0.9, weight_decay=5e-4)\n","            print('üîì Backbone descongelado.')\n","\n","        print(f\"[{epoch:02d}] train_loss={train_loss:.4f} | val_loss={val_loss:.4f}\")\n","\n","        if val_loss < best_val:\n","            best_val = val_loss\n","            torch.save(model.state_dict(), ckpt_path)\n","            print(f\"  ‚Ü≥ ‚úÖ melhor at√© agora (salvo em {ckpt_path})\")\n"],"metadata":{"id":"eSMxJCAMMvOT","executionInfo":{"status":"ok","timestamp":1762495427471,"user_tz":180,"elapsed":1,"user":{"displayName":"Luis Felipe","userId":"08242572504466589884"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["## Inicia treinamento\n","\n","Inicia primeira rodada de treinamento com lr=0.005, momenttum=0.9 e decaimento de 5^(e^-4)"],"metadata":{"id":"qk05C2HKNTgA"}},{"cell_type":"code","source":["import numpy as np, torch\n","from pycocotools.cocoeval import COCOeval\n","\n","def _xyxy_to_xywh(b):\n","    x1,y1,x2,y2 = b\n","    return [float(x1), float(y1), float(x2-x1), float(y2-y1)]\n","\n","@torch.no_grad()\n","def eval_coco_shim(model, data_loader, iou_type=\"bbox\", score_thr=0.0, max_dets=100):\n","    device = next(model.parameters()).device\n","    model.eval()\n","    ds = data_loader.dataset\n","    cocoGt = ds.coco  # precisa existir (seu dataset baseado em COCO tem .coco)\n","\n","    preds = []\n","    for images, targets in data_loader:\n","        img_ids = [int(t[\"image_id\"]) for t in targets]\n","        # blindagem: float32 [0,1]\n","        images  = [(im.float()/255.0 if im.dtype!=torch.float32 else im).to(device) for im in images]\n","        outputs = model(images)\n","\n","        for img_id, out in zip(img_ids, outputs):\n","            boxes  = out[\"boxes\"].detach().cpu().numpy()\n","            scores = out[\"scores\"].detach().cpu().numpy()\n","            labels = out[\"labels\"].detach().cpu().numpy()  # seus labels cont√≠guos (1..K) ou 1 (single-class)\n","\n","            if score_thr > 0:\n","                keep = scores >= score_thr\n","                boxes, scores, labels = boxes[keep], scores[keep], labels[keep]\n","            if max_dets is not None and len(scores) > max_dets:\n","                order = np.argsort(-scores)[:max_dets]\n","                boxes, scores, labels = boxes[order], scores[order], labels[order]\n","\n","            for b, s, c in zip(boxes, scores, labels):\n","                preds.append({\n","                    \"image_id\": img_id,\n","                    \"category_id\": int(c),      # IMPORTANT: deve bater com ids do seu JSON (cont√≠guos ou originais)\n","                    \"bbox\": _xyxy_to_xywh(b.tolist()),\n","                    \"score\": float(s)\n","                })\n","\n","    if len(preds) == 0:\n","        # nada previsto -> devolve zeros\n","        return np.zeros(12, dtype=float), None\n","\n","    cocoDt = cocoGt.loadRes(preds)\n","    ev = COCOeval(cocoGt, cocoDt, iou_type)\n","    ev.evaluate(); ev.accumulate(); ev.summarize()\n","    return ev.stats, ev\n"],"metadata":{"id":"w5nSJXkY92oT","executionInfo":{"status":"ok","timestamp":1762496313914,"user_tz":180,"elapsed":15,"user":{"displayName":"Luis Felipe","userId":"08242572504466589884"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["def coco_ap50_per_class(cocoEval):\n","    import numpy as np\n","    if cocoEval is None:\n","        return []\n","    precisions = cocoEval.eval['precision']  # [TxRxKxAxM]\n","    i = np.where(np.isclose(cocoEval.params.iouThrs, 0.5))[0][0]\n","    pr = precisions[i, :, :, 0, -1]          # [R, K]\n","    aps = np.nanmean(pr, axis=0)             # [K]\n","    cat_ids = cocoEval.params.catIds\n","    id_to_name = {c['id']: c['name'] for c in cocoEval.cocoGt.loadCats(cat_ids)}\n","    return [(cid, id_to_name.get(cid, str(cid)), float(ap) if np.isfinite(ap) else 0.0)\n","            for cid, ap in zip(cat_ids, aps)]\n"],"metadata":{"id":"QhVH5YGE96Iu","executionInfo":{"status":"ok","timestamp":1762496325683,"user_tz":180,"elapsed":3,"user":{"displayName":"Luis Felipe","userId":"08242572504466589884"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["def fit_map(model, train_loader, val_loader, optimizer, scaler, scheduler,\n","            epochs=10, ckpt_path=\"best.pth\", score_thr_eval=0.0):\n","    best_ap50 = -1.0\n","    for epoch in range(1, epochs+1):\n","        # ===== treino =====\n","        model.train()\n","        running = 0.0\n","        for imgs, targets in train_loader:\n","            imgs = [(im.float()/255.0 if im.dtype!=torch.float32 else im).to(device) for im in imgs]\n","            targets = [{k: v.to(device) for k,v in t.items()} for t in targets]\n","\n","            optimizer.zero_grad(set_to_none=True)\n","            with torch.cuda.amp.autocast():\n","                loss_dict = model(imgs, targets)\n","                loss = sum(loss_dict.values())\n","            scaler.scale(loss).backward()\n","            scaler.step(optimizer)\n","            scaler.update()\n","            running += loss.item()\n","\n","        scheduler.step()\n","        train_loss = running / max(1, len(train_loader))\n","\n","        # ===== avalia√ß√£o (mAP) =====\n","        stats, ev = eval_coco_shim(model, val_loader, score_thr=score_thr_eval)\n","        ap50 = float(stats[1]) if stats is not None and len(stats) >= 2 else 0.0\n","\n","        print(f\"[{epoch:02d}] train_loss={train_loss:.4f} | AP50(val)={ap50:.3f}\")\n","        if ev is not None:\n","            per_cls = coco_ap50_per_class(ev)\n","            if per_cls:\n","                txt = \" | \".join([f\"{name}:{ap:.3f}\" for _,name,ap in per_cls])\n","                print(\"  AP50 por classe:\", txt)\n","\n","        # ===== checkpoint pelo AP50 =====\n","        if ap50 > best_ap50:\n","            best_ap50 = ap50\n","            torch.save(model.state_dict(), ckpt_path)\n","            print(f\"  ‚Ü≥ ‚úÖ melhor at√© agora (AP50={best_ap50:.3f}) salvo em {ckpt_path}\")\n"],"metadata":{"id":"k_S4Lyic98Bj","executionInfo":{"status":"ok","timestamp":1762496334101,"user_tz":180,"elapsed":8,"user":{"displayName":"Luis Felipe","userId":"08242572504466589884"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# 2.1 ‚Äì congele o backbone por 2-3 √©pocas para estabilizar\n","for p in model.backbone.body.parameters():\n","    p.requires_grad = False\n","\n","params = [p for p in model.parameters() if p.requires_grad]\n","optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=5e-4)\n","\n","# Cosine Annealing simples; alternativa: StepLR( step_size=8, gamma=0.1 )\n","scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=20)\n","scaler = torch.cuda.amp.GradScaler()"],"metadata":{"collapsed":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"tmy6F-hwNg_x","executionInfo":{"status":"ok","timestamp":1762495453440,"user_tz":180,"elapsed":16,"user":{"displayName":"Luis Felipe","userId":"08242572504466589884"}},"outputId":"11fb6684-446a-42dd-f50b-1796e74829f9"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3059598682.py:10: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  scaler = torch.cuda.amp.GradScaler()\n"]}]},{"cell_type":"code","source":["fit(model, train_loader, val_loader, optimizer, scaler, scheduler, epochs=20, ckpt_path=\"/content/drive/MyDrive/TCC/checkpoints/fasterrcnn_combined_ds_ft_bb.pth\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":367},"id":"Uowk8BJbNVt8","executionInfo":{"status":"error","timestamp":1762496393695,"user_tz":180,"elapsed":17988,"user":{"displayName":"Luis Felipe","userId":"08242572504466589884"}},"outputId":"bbe6a2b4-74df-473f-f225-1bcbcc22f5ef"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-71931217.py:13: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast():\n"]},{"output_type":"error","ename":"AttributeError","evalue":"'ConcatDataset' object has no attribute 'coco'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-839140252.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfit_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/TCC/checkpoints/fasterrcnn_combined_ds_ft_bb_2.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipython-input-71931217.py\u001b[0m in \u001b[0;36mfit_map\u001b[0;34m(model, train_loader, val_loader, optimizer, scaler, scheduler, epochs, ckpt_path, score_thr_eval)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# ===== avalia√ß√£o (mAP) =====\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mstats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_coco_shim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_thr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscore_thr_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0map50\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mstats\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-1343069988.py\u001b[0m in \u001b[0;36meval_coco_shim\u001b[0;34m(model, data_loader, iou_type, score_thr, max_dets)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mcocoGt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoco\u001b[0m  \u001b[0;31m# precisa existir (seu dataset baseado em COCO tem .coco)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'ConcatDataset' object has no attribute 'coco'"]}]},{"cell_type":"markdown","source":["## Avalia√ß√£o primeiro treinamento"],"metadata":{"id":"_qsmYYr6Ro6y"}},{"cell_type":"markdown","source":["IoU, matching e AP por classe"],"metadata":{"id":"DRnjvIM4Rrhd"}},{"cell_type":"code","source":["import os, math, pathlib\n","import numpy as np\n","import torch\n","import cv2\n","\n","ID_TO_NAME = {1: \"Piscina\", 2: \"CaixaDagua\"}\n","\n","def iou_matrix(boxes1, boxes2):\n","    # boxes: [N,4] e [M,4] no formato [x1,y1,x2,y2]\n","    if boxes1.numel() == 0 or boxes2.numel() == 0:\n","        return torch.zeros((boxes1.shape[0], boxes2.shape[0]))\n","    x11, y11, x12, y12 = boxes1[:,0], boxes1[:,1], boxes1[:,2], boxes1[:,3]\n","    x21, y21, x22, y22 = boxes2[:,0], boxes2[:,1], boxes2[:,2], boxes2[:,3]\n","    xa = torch.maximum(x11[:,None], x21[None,:])\n","    ya = torch.maximum(y11[:,None], y21[None,:])\n","    xb = torch.minimum(x12[:,None], x22[None,:])\n","    yb = torch.minimum(y12[:,None], y22[None,:])\n","    inter = (xb - xa).clamp(min=0) * (yb - ya).clamp(min=0)\n","    area1 = (x12 - x11).clamp(min=0) * (y12 - y11).clamp(min=0)\n","    area2 = (x22 - x21).clamp(min=0) * (y22 - y21).clamp(min=0)\n","    union = area1[:,None] + area2[None,:] - inter\n","    return inter / union.clamp(min=1e-9)\n","\n","def average_precision(scores, tps, fps, npos):\n","    # Ordena por score desc, acumula TP/FP e integra PR\n","    if len(scores) == 0:\n","        return 0.0, {\"precision\":[], \"recall\":[], \"scores\":[]}\n","    order = np.argsort(-scores)\n","    tps = np.array(tps)[order].astype(np.float32)\n","    fps = np.array(fps)[order].astype(np.float32)\n","\n","    tp_cum = np.cumsum(tps)\n","    fp_cum = np.cumsum(fps)\n","    recall = tp_cum / max(npos, 1)\n","    precision = tp_cum / np.maximum(tp_cum + fp_cum, 1e-9)\n","\n","    # AP pela integra√ß√£o cont√≠nua (VOC moderno)\n","    # For√ßa envelope de precis√£o n√£o-crescente\n","    mrec = np.concatenate(([0.0], recall, [1.0]))\n","    mpre = np.concatenate(([0.0], precision, [0.0]))\n","    for i in range(mpre.size - 1, 0, -1):\n","        mpre[i-1] = max(mpre[i-1], mpre[i])\n","    # Pega pontos onde recall muda\n","    idx = np.where(mrec[1:] != mrec[:-1])[0]\n","    ap = float(np.sum((mrec[idx + 1] - mrec[idx]) * mpre[idx + 1]))\n","    return ap, {\"precision\":precision.tolist(), \"recall\":recall.tolist(), \"scores\":scores[order].tolist()}\n"],"metadata":{"id":"pXlx9jPQRvtL","executionInfo":{"status":"ok","timestamp":1762496236976,"user_tz":180,"elapsed":3,"user":{"displayName":"Luis Felipe","userId":"08242572504466589884"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["Avalia√ß√£o por classe (AP@0.50) e salvamento de imagens com boxes"],"metadata":{"id":"F-qh4gS5R1un"}},{"cell_type":"code","source":["@torch.no_grad()\n","def evaluate_and_visualize(model, loader, out_dir=\"/content/out\", score_thr=0.25, iou_thr=0.50, max_images_to_save=200):\n","    model.eval()\n","    pathlib.Path(out_dir).mkdir(parents=True, exist_ok=True)\n","\n","    # Acumuladores por classe\n","    classes = [1,2]\n","    scores_by_c = {c: [] for c in classes}\n","    tps_by_c    = {c: [] for c in classes}\n","    fps_by_c    = {c: [] for c in classes}\n","    npos_by_c   = {c: 0  for c in classes}\n","\n","    saved = 0\n","\n","    for imgs, targets in loader:\n","        # move\n","        imgs_cuda = [im.to(device) for im in imgs]\n","        preds = model(imgs_cuda)\n","        preds = [{k: v.detach().cpu() for k,v in p.items()} for p in preds]\n","        tgts  = [{k: v.detach().cpu() for k,v in t.items()} for t in targets]\n","\n","        for img_tensor, pred, tgt in zip(imgs, preds, tgts):\n","            # Contagem de GT por classe\n","            gt_boxes = tgt[\"boxes\"]\n","            gt_labels = tgt[\"labels\"]\n","            for c in classes:\n","                npos_by_c[c] += int((gt_labels==c).sum().item())\n","\n","            # Filtra preds por score\n","            keep = pred[\"scores\"] >= score_thr\n","            pb = pred[\"boxes\"][keep]\n","            pl = pred[\"labels\"][keep]\n","            ps = pred[\"scores\"][keep]\n","\n","            # Matching por classe\n","            for c in classes:\n","                pb_c = pb[pl==c]\n","                ps_c = ps[pl==c]\n","                gt_c = gt_boxes[gt_labels==c]\n","\n","                if len(pb_c)==0:\n","                    continue\n","                # Greedy: ordena por score, faz matching one-to-one por IoU\n","                order = torch.argsort(ps_c, descending=True)\n","                pb_c = pb_c[order]\n","                ps_c = ps_c[order]\n","\n","                matched_gt = torch.zeros(len(gt_c), dtype=torch.bool)\n","                for j, box in enumerate(pb_c):\n","                    if len(gt_c)==0:\n","                        # nenhuma GT daquela classe nessa imagem\n","                        scores_by_c[c].append(float(ps_c[j]))\n","                        tps_by_c[c].append(0)\n","                        fps_by_c[c].append(1)\n","                        continue\n","                    ious = iou_matrix(box.unsqueeze(0), gt_c).squeeze(0)  # [num_gt]\n","                    best_iou, best_idx = (ious.max().item(), int(ious.argmax().item()))\n","                    scores_by_c[c].append(float(ps_c[j]))\n","                    if best_iou >= iou_thr and not matched_gt[best_idx]:\n","                        tps_by_c[c].append(1); fps_by_c[c].append(0)\n","                        matched_gt[best_idx] = True\n","                    else:\n","                        tps_by_c[c].append(0); fps_by_c[c].append(1)\n","\n","            # ====== Visualiza√ß√£o / salvamento ======\n","            if saved < max_images_to_save:\n","                # Converte imagem tensor -> BGR uint8\n","                im = img_tensor.detach().cpu()\n","                if im.dtype==torch.float32:\n","                    # assume [0,1]\n","                    im = (im*255).clamp(0,255).byte()\n","                im = im.permute(1,2,0).numpy()  # HWC, RGB\n","                im = cv2.cvtColor(im, cv2.COLOR_RGB2BGR)\n","\n","                # Desenha GT (tracejado fino)\n","                for b, lab in zip(gt_boxes, gt_labels):\n","                    x1,y1,x2,y2 = map(int, b.tolist())\n","                    color = (0,255,0) if lab.item()==1 else (255,0,0)\n","                    cv2.rectangle(im, (x1,y1), (x2,y2), color, 1, lineType=cv2.LINE_AA)\n","\n","                # Desenha Preds\n","                for b, lab, sc in zip(pb, pl, ps):\n","                    x1,y1,x2,y2 = map(int, b.tolist())\n","                    color = (50,220,50) if lab.item()==1 else (50,50,220)\n","                    cv2.rectangle(im, (x1,y1), (x2,y2), color, 2, lineType=cv2.LINE_AA)\n","                    txt = f\"{ID_TO_NAME.get(int(lab.item()), str(int(lab.item())))} {float(sc):.2f}\"\n","                    cv2.putText(im, txt, (x1, max(y1-5, 0)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2, cv2.LINE_AA)\n","\n","                out_path = os.path.join(out_dir, f\"pred_{saved:05d}.jpg\")\n","                cv2.imwrite(out_path, im)\n","                saved += 1\n","\n","    # Calcula AP@0.50 por classe\n","    results = {}\n","    for c in classes:\n","        ap, curves = average_precision(\n","            np.array(scores_by_c[c], dtype=np.float32),\n","            tps_by_c[c],\n","            fps_by_c[c],\n","            npos_by_c[c]\n","        )\n","        results[c] = {\"AP@0.50\": ap, \"npos\": int(npos_by_c[c])}\n","\n","    return results\n"],"metadata":{"id":"l75smy0wRyFP","executionInfo":{"status":"ok","timestamp":1762496239234,"user_tz":180,"elapsed":15,"user":{"displayName":"Luis Felipe","userId":"08242572504466589884"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["Armazena imagens com boxes nas piscinas e caixas d'agua e salva checkpoint"],"metadata":{"id":"hYJWK1y7dnc9"}},{"cell_type":"code","source":["out = evaluate_and_visualize(model, test_loader, out_dir=\"/content/drive/MyDrive/TCC/out\", score_thr=0.25, iou_thr=0.50, max_images_to_save=10)\n","\n","print(\"==== Resultados por classe (AP@0.50) ====\")\n","for cid, info in out.items():\n","    print(f\"{ID_TO_NAME[cid]:<12}  AP@0.50 = {info['AP@0.50']:.3f}   (GT objs: {info['npos']})\")\n","\n","print(\"Imagens salvas em /content/out (preds em cor forte; GT em tra√ßo fino).\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PBmc9p43R8bf","executionInfo":{"status":"ok","timestamp":1762496313774,"user_tz":180,"elapsed":64064,"user":{"displayName":"Luis Felipe","userId":"08242572504466589884"}},"outputId":"c6b3f62d-05e3-4cc6-c8a9-833970a7bdfb"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["==== Resultados por classe (AP@0.50) ====\n","Piscina       AP@0.50 = 0.743   (GT objs: 1109)\n","CaixaDagua    AP@0.50 = 0.004   (GT objs: 2723)\n","Imagens salvas em /content/out (preds em cor forte; GT em tra√ßo fino).\n"]}]},{"cell_type":"markdown","source":["## Inicia segunda rodade de treinamentos com foco em caixas dagua"],"metadata":{"id":"jkx2ST21eAP4"}},{"cell_type":"code","source":["import random, numpy as np, torch\n","random.seed(42); np.random.seed(42); torch.manual_seed(42); torch.cuda.manual_seed_all(42)\n","torch.backends.cudnn.benchmark = True\n","# opcional (se quiser estabilidade extra):\n","# !pip install -q \"torch==2.4.0\" \"torchvision==0.19.0\"\n"],"metadata":{"id":"6IsWl-xxKuHS","executionInfo":{"status":"ok","timestamp":1762449353209,"user_tz":180,"elapsed":42,"user":{"displayName":"Luis Felipe","userId":"08242572504466589884"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from torch.utils.data import WeightedRandomSampler, DataLoader, ConcatDataset\n","def has_cls2(ds):\n","    flags=[]\n","    for i in range(len(ds)):\n","        _,t=ds[i]; flags.append(2 in t[\"labels\"].tolist())\n","    return np.array(flags, bool)\n","flags = has_cls2(train_ds)\n","weights = np.where(flags, 4.0, 1.0).astype(np.float32)  # 4x mais chance de vir img com caixa\n","sampler = WeightedRandomSampler(weights, num_samples=len(weights), replacement=True)\n","\n","train_loader = DataLoader(train_ds, batch_size=2, sampler=sampler, num_workers=2, pin_memory=True, collate_fn=collate_fn)\n","val_loader   = DataLoader(val_ds,   batch_size=2, shuffle=False,   num_workers=2, pin_memory=True, collate_fn=collate_fn)\n","test_loader  = DataLoader(test_ds,  batch_size=2, shuffle=False,   num_workers=2, pin_memory=True, collate_fn=collate_fn)\n"],"metadata":{"id":"vJZIfH8QKxWi","executionInfo":{"status":"ok","timestamp":1762450090686,"user_tz":180,"elapsed":29090,"user":{"displayName":"Luis Felipe","userId":"08242572504466589884"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["import torch\n","from torchvision.models.detection import fasterrcnn_resnet50_fpn_v2\n","from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","ckpt_path = \"/content/drive/MyDrive/TCC/checkpoints/fasterrcnn_combined_ds_ft.pth\"  # seu arquivo\n","\n","# 1) Recrie a MESMA arquitetura do treino anterior (v2) SEM pesos COCO\n","model = fasterrcnn_resnet50_fpn_v2(weights=None)\n","\n","# 2) Ajuste o head para o mesmo n¬∫ de classes usado no seu projeto\n","NUM_CLASSES = 3  # 0=bg, 1=Piscina, 2=CaixaDagua\n","in_f = model.roi_heads.box_predictor.cls_score.in_features\n","model.roi_heads.box_predictor = FastRCNNPredictor(in_f, NUM_CLASSES)\n","\n","# 3) Carregue o checkpoint de forma robusta (parcial se shapes n√£o baterem)\n","state = torch.load(ckpt_path, map_location=\"cpu\")\n","cur = model.state_dict()\n","filtered = {k:v for k,v in state.items() if k in cur and cur[k].shape == v.shape}\n","cur.update(filtered)\n","missing, unexpected = model.load_state_dict(cur, strict=False)\n","print(\"Aproveitados:\", len(filtered), \"| missing:\", len(missing), \"| unexpected:\", len(unexpected))\n","\n","model.to(device).eval()\n","\n","# 4) Sanidade r√°pida: head coerente e um forward ‚Äúseco‚Äù\n","cs = model.roi_heads.box_predictor.cls_score\n","bp = model.roi_heads.box_predictor.bbox_pred\n","print(\"cls_out, bbox_out =\", cs.out_features, bp.out_features)  # deve ser 3 e 12\n","\n","imgs, _ = next(iter(val_loader))  # use seu val_loader\n","with torch.no_grad():\n","    _ = model([im.to(device) for im in imgs])  # deve passar sem erro\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TdiRwPRJLCYa","executionInfo":{"status":"ok","timestamp":1762449928031,"user_tz":180,"elapsed":2013,"user":{"displayName":"Luis Felipe","userId":"08242572504466589884"}},"outputId":"79e5dfa8-dd08-4fce-dc24-6891cc47c6c4"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Aproveitados: 404 | missing: 0 | unexpected: 0\n","cls_out, bbox_out = 3 12\n"]}]},{"cell_type":"code","source":["# pr√≥ximos do default; depois abrimos o funil se precisar\n","model.rpn.pre_nms_top_n_train  = 2000\n","model.rpn.post_nms_top_n_train = 1000\n","model.rpn.pre_nms_top_n_test   = 1000\n","model.rpn.post_nms_top_n_test  = 1000\n","model.roi_heads.batch_size_per_image = 256\n","model.roi_heads.positive_fraction    = 0.25"],"metadata":{"id":"ZQxb3QGaNeJm","executionInfo":{"status":"ok","timestamp":1762450090690,"user_tz":180,"elapsed":15,"user":{"displayName":"Luis Felipe","userId":"08242572504466589884"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["import contextlib, torch\n","USE_CUDA = torch.cuda.is_available()\n","amp_ctx = (torch.amp.autocast('cuda') if USE_CUDA else contextlib.nullcontext())\n","\n","@torch.no_grad()\n","def eval_ap_c2(model, val_loader):\n","    # sua evaluate_and_visualize deve aceitar out_dir=None e max_images_to_save=0\n","    res = evaluate_and_visualize(model, val_loader, out_dir=\"/content/drive/MyDrive/TCC/out\", score_thr=0.25, iou_thr=0.50, max_images_to_save=0)\n","    return res.get(2, {}).get(\"AP@0.50\", 0.0)\n","\n","def train_epochs(model, train_loader, val_loader, opt, sched, epochs, ckpt_path):\n","    best = -1.0\n","    dev = next(model.parameters()).device\n","    for ep in range(1, epochs+1):\n","        model.train(); run=0.0\n","        for imgs, tgts in train_loader:\n","            imgs=[im.to(dev) for im in imgs]\n","            tgts=[{k:v.to(dev) for k,v in t.items()} for t in tgts]\n","            opt.zero_grad(set_to_none=True)\n","            with amp_ctx:\n","                loss = sum(model(imgs, tgts).values())\n","            loss.backward(); opt.step()\n","            run += loss.item()\n","        sched.step()\n","        model.eval()\n","        ap_c2 = eval_ap_c2(model, val_loader)\n","        print(f\"[{ep:02d}] loss={run/len(train_loader):.4f} | AP50(Caixa)={ap_c2:.3f}\")\n","        if ap_c2 > best:\n","            best = ap_c2\n","            torch.save(model.state_dict(), ckpt_path)\n","            print(f\"  ‚Üë melhor AP50(Caixa) {best:.3f} salvo em {ckpt_path}\")\n","    return best\n","\n","# Est√°gio A ‚Äî congelar backbone (3 √©pocas r√°pidas)\n","for p in model.backbone.body.parameters(): p.requires_grad = False\n","optA  = torch.optim.SGD([p for p in model.parameters() if p.requires_grad], lr=2e-3, momentum=0.9, weight_decay=5e-4)\n","schA  = torch.optim.lr_scheduler.MultiStepLR(optA, milestones=[3], gamma=0.1)\n","bestA = train_epochs(model, train_loader, val_loader, optA, schA, epochs=3, ckpt_path=\"/content/drive/MyDrive/TCC/checkpoints/best_c2_heads.pth\")\n","\n","# Est√°gio B ‚Äî liberar backbone (refino 10‚Äì12 √©pocas, LR menor)\n","for p in model.backbone.body.parameters(): p.requires_grad = True\n","optB  = torch.optim.SGD([p for p in model.parameters() if p.requires_grad], lr=8e-4, momentum=0.9, weight_decay=5e-4)\n","schB  = torch.optim.lr_scheduler.MultiStepLR(optB, milestones=[8,12], gamma=0.5)\n","bestB = train_epochs(model, train_loader, val_loader, optB, schB, epochs=12, ckpt_path=\"/content/drive/MyDrive/TCC/checkpoints/best_c2_full.pth\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"X1gWVECkNjhH","executionInfo":{"status":"ok","timestamp":1762450667409,"user_tz":180,"elapsed":377112,"user":{"displayName":"Luis Felipe","userId":"08242572504466589884"}},"outputId":"868d9efb-9c77-40f6-a04e-bfa5fa2911af"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stderr","text":["Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b5b58b94fe0>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n","    if w.is_alive():\n","       ^^^^^^^^^^^^\n","  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","AssertionError: can only test a child process\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b5b58b94fe0>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n","    if w.is_alive():\n","       ^^^^^^^^^^^^\n","  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","AssertionError: can only test a child process\n"]},{"output_type":"stream","name":"stdout","text":["[01] loss=0.6114 | AP50(Caixa)=0.101\n","  ‚Üë melhor AP50(Caixa) 0.101 salvo em /content/drive/MyDrive/TCC/checkpoints/best_c2_heads.pth\n","[02] loss=0.6036 | AP50(Caixa)=0.070\n","[03] loss=0.6092 | AP50(Caixa)=0.054\n","[01] loss=0.5615 | AP50(Caixa)=0.036\n","  ‚Üë melhor AP50(Caixa) 0.036 salvo em /content/drive/MyDrive/TCC/checkpoints/best_c2_full.pth\n","[02] loss=0.5573 | AP50(Caixa)=0.043\n","  ‚Üë melhor AP50(Caixa) 0.043 salvo em /content/drive/MyDrive/TCC/checkpoints/best_c2_full.pth\n","[03] loss=0.5669 | AP50(Caixa)=0.099\n","  ‚Üë melhor AP50(Caixa) 0.099 salvo em /content/drive/MyDrive/TCC/checkpoints/best_c2_full.pth\n","[04] loss=0.5435 | AP50(Caixa)=0.029\n","[05] loss=0.5473 | AP50(Caixa)=0.019\n","[06] loss=0.5468 | AP50(Caixa)=0.021\n","[07] loss=0.5500 | AP50(Caixa)=0.044\n","[08] loss=0.5445 | AP50(Caixa)=0.045\n","[09] loss=0.5342 | AP50(Caixa)=0.022\n","[10] loss=0.5357 | AP50(Caixa)=0.072\n","[11] loss=0.5378 | AP50(Caixa)=0.034\n","[12] loss=0.5340 | AP50(Caixa)=0.046\n"]}]},{"cell_type":"code","source":["model.rpn.pre_nms_top_n_train  = 4000\n","model.rpn.post_nms_top_n_train = 2000\n","model.rpn.pre_nms_top_n_test   = 2000\n","model.rpn.post_nms_top_n_test  = 1500\n","model.roi_heads.batch_size_per_image = 512\n","model.roi_heads.positive_fraction    = 0.5\n"],"metadata":{"id":"2HHegQf_Nv4N","executionInfo":{"status":"ok","timestamp":1762450746258,"user_tz":180,"elapsed":15,"user":{"displayName":"Luis Felipe","userId":"08242572504466589884"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["model.load_state_dict(torch.load(\"/content/drive/MyDrive/TCC/checkpoints/best_c2_full.pth\", map_location=next(model.parameters()).device))\n","model.eval()\n","res_test = evaluate_and_visualize(model, test_loader, out_dir=\"/content/out_v2\", score_thr=0.25, iou_thr=0.50, max_images_to_save=200)\n","print(\"TEST AP50:\", {\"Piscina\":res_test[1][\"AP@0.50\"], \"Caixa\":res_test[2][\"AP@0.50\"]})\n","print(\"Imagens em /content/out_v2\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kGohU8BtQDEd","executionInfo":{"status":"ok","timestamp":1762450801514,"user_tz":180,"elapsed":16347,"user":{"displayName":"Luis Felipe","userId":"08242572504466589884"}},"outputId":"d430e4ed-5196-4607-c63d-69dc1cbd6c75"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["TEST AP50: {'Piscina': 0.5377687034308409, 'Caixa': 0.04010817213592527}\n","Imagens em /content/out_v2\n"]}]},{"cell_type":"markdown","source":["## Adiciona camada de attention"],"metadata":{"id":"nJLvv9V-Qw2n"}},{"cell_type":"markdown","source":["Class AttnWoMLPHead"],"metadata":{"id":"eqg66wYETNux"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class AttnTwoMLPHead(nn.Module):\n","    \"\"\"\n","    Head para Faster R-CNN com aten√ß√£o nas features de cada RoI.\n","    Espera tensores N x C x H x W (normalmente H=W=7, C=256).\n","    Pipeline:\n","      [N, C, 7, 7] --(flatten spatial->tokens)--> [N, 49, C]\n","      --(LayerNorm + MultiheadAttention)--> [N, 49, C]\n","      --(mean pool em tokens)--> [N, C]\n","      --(MLP 2 camadas)--> [N, representation_size]\n","    \"\"\"\n","    def __init__(self, in_channels: int, resolution: int = 7,\n","                 representation_size: int = 1024, num_heads: int = 8,\n","                 attn_dropout: float = 0.0, mlp_dropout: float = 0.1):\n","        super().__init__()\n","        self.in_channels = in_channels\n","        self.resolution  = resolution\n","        self.num_tokens  = resolution * resolution\n","        self.embed_dim   = in_channels\n","        self.representation_size = representation_size\n","\n","        self.ln1 = nn.LayerNorm(self.embed_dim)\n","        self.attn = nn.MultiheadAttention(\n","            embed_dim=self.embed_dim,\n","            num_heads=num_heads,\n","            dropout=attn_dropout,\n","            batch_first=True,   # usa [N, S, E]\n","        )\n","        self.ln2 = nn.LayerNorm(self.embed_dim)\n","\n","        # MLP igual ao TwoMLPHead (duas FCs) depois do pooling dos tokens\n","        self.fc6 = nn.Linear(self.embed_dim, representation_size)\n","        self.fc7 = nn.Linear(representation_size, representation_size)\n","        self.drop = nn.Dropout(mlp_dropout)\n","        self.out_features = representation_size  # ajuda na recomposi√ß√£o do predictor\n","\n","        # inicializa√ß√µes est√°veis\n","        nn.init.xavier_uniform_(self.fc6.weight); nn.init.zeros_(self.fc6.bias)\n","        nn.init.xavier_uniform_(self.fc7.weight); nn.init.zeros_(self.fc7.bias)\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        # x: [N, C, H, W]  (H=W=self.resolution)\n","        N, C, H, W = x.shape\n","        assert C == self.in_channels and H == self.resolution and W == self.resolution, \\\n","            f\"shape inesperada: {x.shape}, esperado: [N,{self.in_channels},{self.resolution},{self.resolution}]\"\n","\n","        # 1) vira tokens: [N, S=H*W, C]\n","        x = x.reshape(N, C, H * W).transpose(1, 2)  # [N, S, C]\n","\n","        # 2) MHSA (pr√©-norm) + residual\n","        h = self.ln1(x)\n","        attn_out, _ = self.attn(h, h, h, need_weights=False)  # [N, S, C]\n","        x = x + attn_out\n","\n","        # 3) p√≥s-attn norm (leve estabiliza√ß√£o)\n","        x = self.ln2(x)\n","\n","        # 4) pool sobre tokens (mean) -> [N, C]\n","        x = x.mean(dim=1)\n","\n","        # 5) MLP 2 camadas\n","        x = F.relu(self.fc6(x))\n","        x = self.drop(x)\n","        x = F.relu(self.fc7(x))\n","        return x"],"metadata":{"id":"riOYSvpUUMVT","executionInfo":{"status":"ok","timestamp":1762451851086,"user_tz":180,"elapsed":43,"user":{"displayName":"Luis Felipe","userId":"08242572504466589884"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["import math\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchvision.models.detection import fasterrcnn_resnet50_fpn_v2\n","from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# 1) crie seu modelo v2 (se quiser, pode usar pesos COCO e depois trocar head)\n","model = fasterrcnn_resnet50_fpn_v2(weights=None)  # ou use COCO_V1 se preferir warm-start no backbone\n","\n","# 2) substitui a box_head pelo head com aten√ß√£o\n","roi_pool_res = model.roi_heads.box_roi_pool.output_size[0]   # normalmente 7\n","C_backbone   = model.backbone.out_channels                    # normalmente 256\n","\n","attn_head = AttnTwoMLPHead(\n","    in_channels=C_backbone,\n","    resolution=roi_pool_res,\n","    representation_size=1024,  # mantenha 1024 para compat com predictor padr√£o\n","    num_heads=8,               # voc√™ pode testar 4/8/16\n","    attn_dropout=0.0,\n","    mlp_dropout=0.1,\n",")\n","model.roi_heads.box_head = attn_head\n","\n","# 3) reconstroi o predictor para 3 classes (bg + piscina + caixa)\n","in_features = attn_head.out_features  # 1024\n","model.roi_heads.box_predictor = FastRCNNPredictor(in_features, 3)\n","\n","model.to(device)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"_825lFq9TTXZ","executionInfo":{"status":"ok","timestamp":1762451856777,"user_tz":180,"elapsed":941,"user":{"displayName":"Luis Felipe","userId":"08242572504466589884"}},"outputId":"c92768cb-7eb0-4360-f403-ee5a12a59832"},"execution_count":47,"outputs":[{"output_type":"execute_result","data":{"text/plain":["FasterRCNN(\n","  (transform): GeneralizedRCNNTransform(\n","      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n","  )\n","  (backbone): BackboneWithFPN(\n","    (body): IntermediateLayerGetter(\n","      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","      (layer1): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","      (layer2): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (3): Bottleneck(\n","          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","      (layer3): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (3): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (4): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (5): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","      (layer4): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","    )\n","    (fpn): FeaturePyramidNetwork(\n","      (inner_blocks): ModuleList(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","        (2): Conv2dNormActivation(\n","          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","        (3): Conv2dNormActivation(\n","          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (layer_blocks): ModuleList(\n","        (0-3): 4 x Conv2dNormActivation(\n","          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (extra_blocks): LastLevelMaxPool()\n","    )\n","  )\n","  (rpn): RegionProposalNetwork(\n","    (anchor_generator): AnchorGenerator()\n","    (head): RPNHead(\n","      (conv): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","          (1): ReLU(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","          (1): ReLU(inplace=True)\n","        )\n","      )\n","      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n","      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","  )\n","  (roi_heads): RoIHeads(\n","    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n","    (box_head): AttnTwoMLPHead(\n","      (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","      (attn): MultiheadAttention(\n","        (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n","      )\n","      (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","      (fc6): Linear(in_features=256, out_features=1024, bias=True)\n","      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n","      (drop): Dropout(p=0.1, inplace=False)\n","    )\n","    (box_predictor): FastRCNNPredictor(\n","      (cls_score): Linear(in_features=1024, out_features=3, bias=True)\n","      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":47}]},{"cell_type":"code","source":["state = torch.load(\"/content/drive/MyDrive/TCC/checkpoints/fasterrcnn_combined_ds_ft.pth\", map_location=\"cpu\")\n","cur = model.state_dict()\n","filtered = {k:v for k,v in state.items() if k in cur and cur[k].shape == v.shape}\n","cur.update(filtered)\n","model.load_state_dict(cur, strict=False)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9TUxeL5NUTav","executionInfo":{"status":"ok","timestamp":1762451946893,"user_tz":180,"elapsed":281,"user":{"displayName":"Luis Felipe","userId":"08242572504466589884"}},"outputId":"cb141417-c987-4254-9f21-89f3674f4634"},"execution_count":48,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":48}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","class CBAMv2(nn.Module):\n","    version = \"cbam_v2_safe_max\"  # tag p/ debug\n","\n","    def __init__(self, channels, reduction=16, kernel_size=7):\n","        super().__init__()\n","        self.mlp = nn.Sequential(\n","            nn.Linear(channels, channels // reduction),\n","            nn.ReLU(inplace=True),\n","            nn.Linear(channels // reduction, channels),\n","        )\n","        self.conv_spatial = nn.Conv2d(2, 1, kernel_size, padding=kernel_size // 2, bias=False)\n","\n","    def forward(self, x):\n","        # x: [N, C, H, W]\n","        N, C, H, W = x.shape\n","\n","        # Channel attention (usar max em 2 etapas)\n","        avg_pool = torch.mean(x, dim=(2, 3), keepdim=True)                     # [N,C,1,1]\n","        max_pool = torch.max(torch.max(x, dim=2, keepdim=True)[0], dim=3, keepdim=True)[0]  # [N,C,1,1]\n","\n","        avg_w = self.mlp(avg_pool.flatten(1))                                  # [N,C]\n","        max_w = self.mlp(max_pool.flatten(1))                                  # [N,C]\n","        ch_attn = torch.sigmoid(avg_w + max_w).view(N, C, 1, 1)                # [N,C,1,1]\n","        x = x * ch_attn\n","\n","        # Spatial attention (usar max 1D)\n","        avg_map = torch.mean(x, dim=1, keepdim=True)                           # [N,1,H,W]\n","        max_map = torch.max(x, dim=1, keepdim=True)[0]                         # [N,1,H,W]\n","        s = torch.cat([avg_map, max_map], dim=1)                               # [N,2,H,W]\n","        sp_attn = torch.sigmoid(self.conv_spatial(s))                          # [N,1,H,W]\n","        return x * sp_attn\n"],"metadata":{"id":"Pnu5EnG-VCmW","executionInfo":{"status":"ok","timestamp":1762453365130,"user_tz":180,"elapsed":41,"user":{"displayName":"Luis Felipe","userId":"08242572504466589884"}}},"execution_count":75,"outputs":[]},{"cell_type":"code","source":["class FPNWithCBAMv4(nn.Module):\n","    version = \"fpn_with_cbam_v4_ignore_pool\"\n","    def __init__(self, fpn_core):\n","        super().__init__()\n","        self.fpn = fpn_core\n","        self.cbam = nn.ModuleDict()  # criaremos por n√≠vel quando necess√°rio\n","\n","    def forward(self, x):\n","        feats = self.fpn(x)   # OrderedDict, e.g. ['0','1','2','3','pool']\n","        out = {}\n","        for k, v in feats.items():\n","            if isinstance(k, str) and k == \"pool\":\n","                out[k] = v\n","                continue\n","            key = str(k)\n","            if key not in self.cbam:\n","                m = CBAMv2(v.shape[1])\n","                m.to(v.device)                      # <<< garante device certo\n","                self.cbam[key] = m\n","            else:\n","                # se o m√≥dulo existir mas estiver em outro device, mova-o\n","                mod = self.cbam[key]\n","                if next(mod.parameters()).device != v.device:\n","                    mod.to(v.device)                # <<< realoca para o device do tensor\n","            out[k] = self.cbam[key](v)\n","        return out\n"],"metadata":{"id":"D5ANSpNzWGYQ","executionInfo":{"status":"ok","timestamp":1762454205493,"user_tz":180,"elapsed":43,"user":{"displayName":"Luis Felipe","userId":"08242572504466589884"}}},"execution_count":94,"outputs":[]},{"cell_type":"code","source":["from torchvision.models.detection import fasterrcnn_resnet50_fpn_v2\n","from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n","\n","device = next(model.parameters()).device if 'model' in globals() else ('cuda' if torch.cuda.is_available() else 'cpu')\n","if isinstance(device, str):\n","    device = torch.device(device)\n","\n","# (Re)crie o modelo base se preferir limpar estado anterior, ou apenas reconstrua a FPN\n","# model = fasterrcnn_resnet50_fpn_v2(weights=None).to(device)\n","\n","# pegue o n√∫cleo da FPN e re-encape com v4\n","fpn_core = model.backbone.fpn.fpn if hasattr(model.backbone.fpn, \"fpn\") else model.backbone.fpn\n","model.backbone.fpn = FPNWithCBAMv4(fpn_core)\n","\n","# reforce o head (3 classes) caso tenha refeito o modelo\n","in_f = model.roi_heads.box_predictor.cls_score.in_features\n","model.roi_heads.box_predictor = FastRCNNPredictor(in_f, 3)\n","model.to(device)\n","\n","print(\"FPN wrapper:\", getattr(model.backbone.fpn, \"version\", None))\n","print(\"CBAM submodules:\", list(model.backbone.fpn.cbam.keys()))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"rW79-D5waOAn","executionInfo":{"status":"ok","timestamp":1762454217119,"user_tz":180,"elapsed":9,"user":{"displayName":"Luis Felipe","userId":"08242572504466589884"}},"outputId":"f2a70760-11b2-47e8-d8de-6c70d24e9910"},"execution_count":95,"outputs":[{"output_type":"stream","name":"stdout","text":["FPN wrapper: fpn_with_cbam_v4_ignore_pool\n","CBAM submodules: []\n"]}]},{"cell_type":"code","source":["model.eval()\n","imgs, _ = next(iter(val_loader))\n","with torch.no_grad():\n","    _ = model([im.to(device) for im in imgs])\n","print(\"‚úÖ Forward eval passou (CBAM v4, pool ignorado)\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X1b_nvYBcXgU","executionInfo":{"status":"ok","timestamp":1762454221913,"user_tz":180,"elapsed":1217,"user":{"displayName":"Luis Felipe","userId":"08242572504466589884"}},"outputId":"6788b85c-a1a2-48d5-fa54-929ca65e7791"},"execution_count":96,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Forward eval passou (CBAM v4, pool ignorado)\n"]}]},{"cell_type":"code","source":["# Est√°gio A ‚Äî backbone congelado\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","for p in model.backbone.body.parameters(): p.requires_grad = False\n","optA = torch.optim.SGD([p for p in model.parameters() if p.requires_grad], lr=8e-4, momentum=0.9, weight_decay=5e-4)\n","schA = torch.optim.lr_scheduler.MultiStepLR(optA, milestones=[3], gamma=0.1)\n","bestA = train_epochs(model, train_loader, val_loader, optA, schA, epochs=3,\n","                     ckpt_path=\"/content/drive/MyDrive/TCC/checkpoints/attn_heads.pth\")\n","\n","# Est√°gio B ‚Äî libera backbone\n","for p in model.backbone.body.parameters(): p.requires_grad = True\n","optB = torch.optim.SGD([p for p in model.parameters() if p.requires_grad], lr=6e-4, momentum=0.9, weight_decay=5e-4)\n","schB = torch.optim.lr_scheduler.MultiStepLR(optB, milestones=[8,12], gamma=0.5)\n","bestB = train_epochs(model, train_loader, val_loader, optB, schB, epochs=10,\n","                     ckpt_path=\"/content/drive/MyDrive/TCC/checkpoints/attn_full.pth\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":859},"id":"jmUlHJWwUoc8","executionInfo":{"status":"error","timestamp":1762454438962,"user_tz":180,"elapsed":209499,"user":{"displayName":"Luis Felipe","userId":"08242572504466589884"}},"outputId":"bca73b94-3ae6-4ebf-c962-52ff0ae0cc50"},"execution_count":97,"outputs":[{"output_type":"stream","name":"stdout","text":["[01] loss=2.3442 | AP50(Caixa)=0.000\n","  ‚Üë melhor AP50(Caixa) 0.000 salvo em /content/drive/MyDrive/TCC/checkpoints/attn_heads.pth\n","[02] loss=1.4639 | AP50(Caixa)=0.000\n","[03] loss=1.3004 | AP50(Caixa)=0.000\n","[01] loss=1.2724 | AP50(Caixa)=0.000\n","  ‚Üë melhor AP50(Caixa) 0.000 salvo em /content/drive/MyDrive/TCC/checkpoints/attn_full.pth\n","[02] loss=1.2582 | AP50(Caixa)=0.000\n","[03] loss=1.2382 | AP50(Caixa)=0.000\n","[04] loss=1.1858 | AP50(Caixa)=0.000\n","[05] loss=1.0967 | AP50(Caixa)=0.000\n"]},{"output_type":"stream","name":"stderr","text":["Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b5b58b94fe0>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1628, in _shutdown_workers\n","    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n","  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 149, in join\n","    res = self._popen.wait(timeout)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.12/multiprocessing/popen_fork.py\", line 40, in wait\n","    if not wait([self.sentinel], timeout):\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.12/multiprocessing/connection.py\", line 1136, in wait\n","    ready = selector.select(timeout)\n","            ^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.12/selectors.py\", line 415, in select\n","    fd_event_list = self._selector.poll(timeout)\n","                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","KeyboardInterrupt: \n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1717319253.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0moptB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6e-4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mschB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultiStepLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmilestones\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m bestB = train_epochs(model, train_loader, val_loader, optB, schB, epochs=10,\n\u001b[0m\u001b[1;32m     15\u001b[0m                      ckpt_path=\"/content/drive/MyDrive/TCC/checkpoints/attn_full.pth\")\n","\u001b[0;32m/tmp/ipython-input-3578731520.py\u001b[0m in \u001b[0;36mtrain_epochs\u001b[0;34m(model, train_loader, val_loader, opt, sched, epochs, ckpt_path)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgts\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mimgs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mtgts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtgts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_to_none\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}